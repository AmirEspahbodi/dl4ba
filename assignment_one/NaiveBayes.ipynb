{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (2103, 5)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    word_tokenize(\"test\")\n",
    "except LookupError:\n",
    "    print(\"NLTK 'punkt' resource not found. Downloading...\")\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "try:\n",
    "    dataset = pd.read_csv('../datasets/gcc_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: gcc_data.csv not found. Please ensure the file is in the correct path.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Original dataset shape:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Target Variable (Assignee) Analysis ---\n",
      "Number of unique assignees (classes): 82\n",
      "\n",
      "Top 10 Assignees by bug count:\n",
      "Assignee\n",
      "Tobias Burnus             264\n",
      "Benjamin Kosnik           257\n",
      "Alexandre Petit-Bianco    159\n",
      "Paolo Bonzini             110\n",
      "David Edelsohn             99\n",
      "Alexandre Oliva            95\n",
      "Alan Modra                 89\n",
      "David Malcolm              70\n",
      "Andrew Haley               67\n",
      "Bryce McKinlay             57\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset.dropna(subset=['Assignee'], inplace=True)\n",
    "\n",
    "dataset['Summary'] = dataset['Summary'].fillna('')\n",
    "dataset['Description'] = dataset['Description'].fillna('')\n",
    "\n",
    "temp = []\n",
    "for i in range(len(dataset['Summary'])):\n",
    "    temp.append(\n",
    "        f\"Summary = {dataset['Summary'].iloc[i]} | Description = {dataset['Description'].iloc[i]}\"\n",
    "    )\n",
    "\n",
    "\n",
    "dataset['text_input'] = temp\n",
    "\n",
    "print(\"\\n--- Target Variable (Assignee) Analysis ---\")\n",
    "num_unique_assignees = dataset['Assignee'].nunique()\n",
    "print(f\"Number of unique assignees (classes): {num_unique_assignees}\")\n",
    "\n",
    "print(\"\\nTop 10 Assignees by bug count:\")\n",
    "print(dataset['Assignee'].value_counts().nlargest(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Assignee Analysis ---\n",
      "Number of unique assignees (classes): 82\n",
      "\n",
      "Top 10 Assignees by bug count:\n",
      "Assignee\n",
      "Tobias Burnus             264\n",
      "Benjamin Kosnik           257\n",
      "Alexandre Petit-Bianco    159\n",
      "Paolo Bonzini             110\n",
      "David Edelsohn             99\n",
      "Alexandre Oliva            95\n",
      "Alan Modra                 89\n",
      "David Malcolm              70\n",
      "Andrew Haley               67\n",
      "Bryce McKinlay             57\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Target Variable (Assignee) Analysis ---\n",
    "print(\"\\n--- Assignee Analysis ---\")\n",
    "unique_assignees = dataset['Assignee'].unique()\n",
    "num_classes = len(unique_assignees)\n",
    "print(f\"Number of unique assignees (classes): {num_classes}\")\n",
    "\n",
    "print(\"\\nTop 10 Assignees by bug count:\")\n",
    "print(dataset['Assignee'].value_counts().nlargest(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Stratification failed, possibly due to too few samples in some classes. Splitting without stratification.\n",
      "\n",
      "Train data size: 1472 bug reports\n",
      "Test data size: 631 bug reports\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_data_df, test_data_df = train_test_split(dataset, test_size=0.3, random_state=42, shuffle=True, stratify=dataset['Assignee'])\n",
    "except ValueError:\n",
    "    print(\"Warning: Stratification failed, possibly due to too few samples in some classes. Splitting without stratification.\")\n",
    "    train_data_df, test_data_df = train_test_split(dataset, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train_texts = train_data_df['text_input'].tolist()\n",
    "train_labels = train_data_df['Assignee'].tolist()\n",
    "\n",
    "test_texts = test_data_df['text_input'].tolist()\n",
    "test_labels = test_data_df['Assignee'].tolist()\n",
    "\n",
    "print(f\"\\nTrain data size: {len(train_texts)} bug reports\")\n",
    "print(f\"Test data size: {len(test_texts)} bug reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing training texts...\n",
      "Preprocessing testing texts...\n",
      "\n",
      "Sample of processed training text (first item):\n",
      "summary  gc shouldnt have to scan data section  description  right now the gc has to scan all the data sectionswe should change this so that roots unrelated toclasses must be registered  this should greatlyimprove gc performance seehttpgccgnuorgmljava200311msg00207htmlthis is an incompatible change we should make it alongwith our other abibreaking changes\n"
     ]
    }
   ],
   "source": [
    "# --- Text Preprocessing Function ---\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower() # Ensure it's a string and lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "    # Consider removing digits: text = re.sub(r'\\d+', '', text)\n",
    "    # Consider stemming/lemmatization for more advanced preprocessing\n",
    "    return text\n",
    "\n",
    "print(\"\\nPreprocessing training texts...\")\n",
    "preprocessed_train_texts = [preprocess_text(text) for text in train_texts]\n",
    "print(\"Preprocessing testing texts...\")\n",
    "preprocessed_test_texts = [preprocess_text(text) for text in test_texts]\n",
    "\n",
    "if preprocessed_train_texts:\n",
    "    print(\"\\nSample of processed training text (first item):\")\n",
    "    print(preprocessed_train_texts[0][:500] + \"...\" if len(preprocessed_train_texts[0]) > 500 else preprocessed_train_texts[0])\n",
    "else:\n",
    "    print(\"No training data to process.\")\n",
    "    exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building vocabulary...\n",
      "Vocabulary size: 35799 unique words\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding vocabulary...\")\n",
    "vocabulary = set()\n",
    "for text_tokens in preprocessed_train_texts:\n",
    "    words = word_tokenize(text_tokens)\n",
    "    vocabulary.update(words)\n",
    "V = len(vocabulary)\n",
    "print(f\"Vocabulary size: {V} unique words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating prior probabilities...\n"
     ]
    }
   ],
   "source": [
    "# --- Calculating Prior Probabilities for each Assignee ---\n",
    "print(\"\\nCalculating prior probabilities...\")\n",
    "class_counts = FreqDist(train_labels)\n",
    "total_train_samples = len(train_labels)\n",
    "prior_probs = {assignee: count / total_train_samples for assignee, count in class_counts.items()}\n",
    "\n",
    "# print(\"Prior Probabilities (sample):\")\n",
    "# for i, (assignee, prob) in enumerate(prior_probs.items()):\n",
    "# if i < 5: print(f\"  P({assignee}) = {prob:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating word frequencies per assignee...\n"
     ]
    }
   ],
   "source": [
    "# --- Calculating Conditional Probabilities (Word Frequencies per Assignee) ---\n",
    "print(\"\\nCalculating word frequencies per assignee...\")\n",
    "# word_counts_per_class[assignee] = FreqDist of words for that assignee\n",
    "word_counts_per_class = defaultdict(FreqDist)\n",
    "# total_words_per_class[assignee] = total number of words for that assignee\n",
    "total_words_per_class = defaultdict(int)\n",
    "\n",
    "for text_tokens, label in zip(preprocessed_train_texts, train_labels):\n",
    "    words = word_tokenize(text_tokens)\n",
    "    word_counts_per_class[label].update(words)\n",
    "    total_words_per_class[label] += len(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating conditional word probabilities with Laplace smoothing...\n"
     ]
    }
   ],
   "source": [
    "# --- Calculating Conditional Word Probabilities P(word | Assignee) with Laplace Smoothing ---\n",
    "print(\"\\nCalculating conditional word probabilities with Laplace smoothing...\")\n",
    "# conditional_word_probs[assignee][word] = P(word | assignee)\n",
    "conditional_word_probs = defaultdict(lambda: defaultdict(float))\n",
    "alpha = 1 # Laplace smoothing factor\n",
    "\n",
    "for assignee in unique_assignees: # Iterate over all known assignees\n",
    "    denominator = total_words_per_class[assignee] + alpha * V\n",
    "    for word in vocabulary:\n",
    "        count = word_counts_per_class[assignee][word]\n",
    "        conditional_word_probs[assignee][word] = (count + alpha) / denominator\n",
    "    # Probability for unknown words given a class (not explicitly stored but handled by smoothing)\n",
    "    # This is P(unknown_word | assignee) = alpha / denominator\n",
    "    # We can store this if needed, but typically unknown words in test doc are ignored if not in vocabulary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up Naive Bayes classifier predict function...\n",
      "\n",
      "Predicting assignees for test set...\n",
      "\n",
      "Calculating accuracy...\n",
      "\n",
      "Accuracy on the test set: 33.44%\n"
     ]
    }
   ],
   "source": [
    "# --- Implementing the Naive Bayes Classifier ---\n",
    "print(\"\\nSetting up Naive Bayes classifier predict function...\")\n",
    "def predict_assignee(text_to_classify):\n",
    "    processed_text = preprocess_text(text_to_classify)\n",
    "    words_in_text = word_tokenize(processed_text)\n",
    "    \n",
    "    log_probs_per_assignee = {}\n",
    "\n",
    "    for assignee in unique_assignees: # Iterate through all possible assignees\n",
    "        # Start with log prior probability\n",
    "        # If an assignee had 0 training samples, their prior_prob might be missing or 0.\n",
    "        # Handle cases where an assignee might not be in prior_probs (e.g., appeared only in test set, though unlikely with good split)\n",
    "        # or if prior_prob is 0, log(0) is undefined.\n",
    "        if prior_probs.get(assignee, 0) == 0:\n",
    "            log_probs_per_assignee[assignee] = -float('inf') # Effectively impossible\n",
    "            continue\n",
    "        \n",
    "        log_prob_assignee = math.log(prior_probs[assignee])\n",
    "        \n",
    "        # Add log conditional probabilities for words in the text\n",
    "        for word in words_in_text:\n",
    "            if word in vocabulary: # Only consider words seen in training vocabulary\n",
    "                # If a word was in vocab but never seen for this specific assignee,\n",
    "                # its conditional_word_probs[assignee][word] would use the smoothed value\n",
    "                log_prob_assignee += math.log(conditional_word_probs[assignee][word])\n",
    "            # else: word not in vocabulary, ignore it (standard practice)\n",
    "\n",
    "        log_probs_per_assignee[assignee] = log_prob_assignee\n",
    "        \n",
    "    # Return the assignee with the highest log probability\n",
    "    if not log_probs_per_assignee: # Should not happen if unique_assignees is populated\n",
    "        return None \n",
    "    \n",
    "    # Find assignee with max log probability\n",
    "    best_assignee = max(log_probs_per_assignee, key=log_probs_per_assignee.get)\n",
    "    return best_assignee\n",
    "\n",
    "# --- Predict labels for test texts ---\n",
    "print(\"\\nPredicting assignees for test set...\")\n",
    "predicted_assignees = [predict_assignee(text) for text in preprocessed_test_texts]\n",
    "\n",
    "# --- Calculate Accuracy ---\n",
    "print(\"\\nCalculating accuracy...\")\n",
    "correct_predictions = 0\n",
    "for predicted, actual in zip(predicted_assignees, test_labels):\n",
    "    if predicted == actual:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(test_labels) if len(test_labels) > 0 else 0\n",
    "\n",
    "print(f\"\\nAccuracy on the test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting assignees for test set...\n"
     ]
    }
   ],
   "source": [
    "# --- Predict labels for test texts ---\n",
    "print(\"\\nPredicting assignees for test set...\")\n",
    "predicted_assignees = [predict_assignee(text) for text in preprocessed_test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating accuracy...\n",
      "\n",
      "Accuracy on the test set: 33.44%\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate Accuracy ---\n",
    "print(\"\\nCalculating accuracy...\")\n",
    "correct_predictions = 0\n",
    "for predicted, actual in zip(predicted_assignees, test_labels):\n",
    "    if predicted == actual:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(test_labels) if len(test_labels) > 0 else 0\n",
    "\n",
    "print(f\"\\nAccuracy on the test set: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project-UsGAi-Qg-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
