{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w2LsSBEib4qq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from transformers import BertTokenizerFast, BertForMaskedLM, pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- GloVe Configuration ---\n",
        "GLOVE_FILE_NAME = 'glove.6B.300d.txt'\n",
        "GLOVE_EMBEDDING_DIM = 300\n",
        "GLOVE_PATH = f'./{GLOVE_FILE_NAME}'\n",
        "GLOVE_ZIP_URL = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "GLOVE_LOCAL_ZIP_PATH = './glove.6B.zip'\n",
        "\n",
        "# --- Model & Training Configuration ---\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "BATCH_SIZE = 32 \n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 1e-4\n",
        "NUM_EPOCHS = 10\n",
        "VALID_SET_SIZE = 0.2\n",
        "MIN_CLASS_REPRESENTATION = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing GloVe text file: ./glove.6B.300d.txt\n",
            "Loading GloVe vectors from ./glove.6B.300d.txt with dimension 300...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading GloVe: 400000it [00:13, 29685.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded 400000 word vectors.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# --- GloVe File Handling ---\n",
        "def ensure_glove_file_is_present():\n",
        "    if os.path.exists(GLOVE_PATH):\n",
        "        print(f\"Found existing GloVe text file: {GLOVE_PATH}\")\n",
        "        return True\n",
        "    if not os.path.exists(GLOVE_LOCAL_ZIP_PATH):\n",
        "        print(f\"GloVe zip file {GLOVE_LOCAL_ZIP_PATH} not found. Attempting to download from {GLOVE_ZIP_URL}...\")\n",
        "        try:\n",
        "            response = requests.get(GLOVE_ZIP_URL, stream=True)\n",
        "            response.raise_for_status()\n",
        "            total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
        "            block_size = 1024\n",
        "            with open(GLOVE_LOCAL_ZIP_PATH, 'wb') as file, tqdm(\n",
        "                desc=f\"Downloading {os.path.basename(GLOVE_ZIP_URL)}\",\n",
        "                total=total_size_in_bytes, unit='iB', unit_scale=True, unit_divisor=1024,\n",
        "            ) as bar:\n",
        "                for data in response.iter_content(block_size):\n",
        "                    bar.update(len(data))\n",
        "                    file.write(data)\n",
        "            print(f\"Successfully downloaded {GLOVE_LOCAL_ZIP_PATH}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading GloVe zip file: {e}\")\n",
        "            if os.path.exists(GLOVE_LOCAL_ZIP_PATH): os.remove(GLOVE_LOCAL_ZIP_PATH)\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred during download: {e}\")\n",
        "            if os.path.exists(GLOVE_LOCAL_ZIP_PATH): os.remove(GLOVE_LOCAL_ZIP_PATH)\n",
        "            return False\n",
        "    else:\n",
        "        print(f\"Found existing GloVe zip file: {GLOVE_LOCAL_ZIP_PATH}\")\n",
        "\n",
        "    print(f\"Attempting to extract {GLOVE_FILE_NAME} from {GLOVE_LOCAL_ZIP_PATH}...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(GLOVE_LOCAL_ZIP_PATH, 'r') as zip_ref:\n",
        "            if GLOVE_FILE_NAME in zip_ref.namelist():\n",
        "                zip_ref.extract(GLOVE_FILE_NAME, path=os.path.dirname(GLOVE_PATH) or '.')\n",
        "                print(f\"Successfully extracted {GLOVE_FILE_NAME} to {GLOVE_PATH}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"Error: {GLOVE_FILE_NAME} not found inside {GLOVE_LOCAL_ZIP_PATH}.\")\n",
        "                print(f\"Available files: {zip_ref.namelist()}\")\n",
        "                return False\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: {GLOVE_LOCAL_ZIP_PATH} is a bad zip file. Please delete it and try again.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during extraction: {e}\")\n",
        "        return False\n",
        "\n",
        "if not ensure_glove_file_is_present():\n",
        "    print(\"Could not obtain GloVe file. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "def load_glove_vectors(glove_path, embedding_dim):\n",
        "    print(f\"Loading GloVe vectors from {glove_path} with dimension {embedding_dim}...\")\n",
        "    if not os.path.exists(glove_path):\n",
        "        print(f\"Error: GloVe file not found at {glove_path}.\")\n",
        "        return None\n",
        "    word_to_vec = {}\n",
        "    try:\n",
        "        with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "            for line in tqdm(f, desc=\"Loading GloVe\"):\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "                try:\n",
        "                    vector = np.asarray(values[1:], dtype='float32')\n",
        "                    if len(vector) == embedding_dim:\n",
        "                        word_to_vec[word] = vector\n",
        "                except ValueError:\n",
        "                    pass\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the GloVe file: {e}\")\n",
        "        return None\n",
        "    if not word_to_vec:\n",
        "        print(f\"No word vectors loaded from {glove_path}.\")\n",
        "        return None\n",
        "    print(f\"Successfully loaded {len(word_to_vec)} word vectors.\")\n",
        "    return word_to_vec\n",
        "\n",
        "glove_vectors_map = load_glove_vectors(GLOVE_PATH, GLOVE_EMBEDDING_DIM)\n",
        "\n",
        "unk_embedding = np.random.rand(GLOVE_EMBEDDING_DIM).astype('float32') # Random UNK if not in GloVe\n",
        "if glove_vectors_map:\n",
        "    if '[unk]' in glove_vectors_map: unk_embedding = glove_vectors_map['[unk]']\n",
        "    elif 'unk' in glove_vectors_map: unk_embedding = glove_vectors_map['unk']\n",
        "else:\n",
        "    print(\"GloVe vectors map is empty or not loaded. Using random UNK embedding. Training will be affected.\")\n",
        "    # exit() # Critical error, might be best to exit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "Tokenizer loaded.\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading BERT tokenizer...\")\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "print(\"Tokenizer loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading gcc_data.csv...\n",
            "Original gcc_data shape: (2103, 5)\n",
            "Shape after dropping NA assignees: (2103, 6)\n",
            "Number of unique assignees (classes): 82\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading gcc_data.csv...\")\n",
        "dataset_path = '../datasets/gcc_data.csv'\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(f\"Warning: '{dataset_path}' not found. Trying 'gcc_data.csv' in current directory.\")\n",
        "    dataset_path = 'gcc_data.csv' # Fallback to current directory\n",
        "\n",
        "try:\n",
        "    dataset = pd.read_csv(dataset_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: gcc_data.csv not found at '{dataset_path}' or in the current directory. Please place it correctly.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Original gcc_data shape: {dataset.shape}\")\n",
        "\n",
        "# Basic preprocessing for text columns\n",
        "dataset['Summary'] = dataset['Summary'].fillna('').astype(str)\n",
        "dataset['Description'] = dataset['Description'].fillna('').astype(str)\n",
        "temp = []\n",
        "for i in range(len(dataset['Summary'])):\n",
        "    temp.append(\n",
        "        f\"Summary = {dataset['Summary'].iloc[i]} | Description = {dataset['Description'].iloc[i]}\"\n",
        "    )\n",
        "dataset['text_input'] = temp\n",
        "\n",
        "# Target variable: Assignee. Drop rows with missing Assignee.\n",
        "dataset.dropna(subset=['Assignee'], inplace=True)\n",
        "dataset['Assignee'] = dataset['Assignee'].astype(str) # Ensure assignee names are strings\n",
        "print(f\"Shape after dropping NA assignees: {dataset.shape}\")\n",
        "\n",
        "# Label Encoding for Assignee\n",
        "assignee_encoder = LabelEncoder()\n",
        "dataset['assignee_encoded'] = assignee_encoder.fit_transform(dataset['Assignee'])\n",
        "NUM_ACTUAL_CLS = len(assignee_encoder.classes_)\n",
        "print(f\"Number of unique assignees (classes): {NUM_ACTUAL_CLS}\")\n",
        "if NUM_ACTUAL_CLS <= 1:\n",
        "    print(\"Error: Only one or no classes found after encoding. Cannot train classifier.\")\n",
        "    exit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initializing components for Contextual Word Augmentation...\n",
            "CUDA seems available and initialized. Attempting to use GPU for pipeline.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Masked LM pipeline ('bert-base-uncased') initialized successfully on device: cuda:0.\n",
            "\n",
            "Applying contextual word replacement augmentation to generate approx. 525 new samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Augmenting samples:   0%|          | 1/525 [00:00<03:20,  2.62it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Augmenting samples: 100%|██████████| 525/525 [01:43<00:00,  5.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape of dataset after augmentation: (2626, 8)\n",
            "Number of augmented samples added: 523\n",
            "\n",
            "Example of augmentation:\n",
            "Original text (from index 402): Summary = [4.0 Regression] Aliasing optimisation bug | Description = The attached C++ program triggers an assertion violation when compiled with -O2(it should not).The assertion is not triggered when adding -fno-strict-aliasing, or when removing-O2.  It is also working when slight changes to the program are made (see commentsin the source).  It is the smallest version of the program which allowed me toreproduce the bug, but I did not try to look into the <vector> header.It might be an aliasing bug in <vector>, I don't know.Note that g++ 3.4 works fine.\n",
            "One augmented text for it: Summary = [4.0 Regression] Aliasing optimisation bug | statement = The attached C++ program triggers an assertion only when compiled in -O2(it should not).The assertion is only working when adding -fno-strict-aliasing, or when removing-O2. It is also working when slight changes to the program are made (see commentsin the source). It is my smallest version of the program which allowed me toreproduce the bug, and I did even try to look into the <vector> header.It might be an aliasing bug in <vector>, I don't know.Note : g++ 3.4 works fine.\n",
            "\n",
            "Final dataset size: (2626, 8)\n",
            "Warning: Could not stratify during train_test_split due to: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.. Splitting without stratification.\n",
            "\n",
            "Shape of X_train: (2100,)\n",
            "Shape of X_test: (526,)\n",
            "Train set class distribution (top 5 classes):\n",
            "assignee_encoded\n",
            "71    0.124762\n",
            "16    0.117143\n",
            "6     0.072381\n",
            "59    0.056667\n",
            "5     0.046667\n",
            "Name: proportion, dtype: float64\n",
            "Test set class distribution (top 5 classes):\n",
            "assignee_encoded\n",
            "16    0.129278\n",
            "71    0.112167\n",
            "6     0.100760\n",
            "59    0.053232\n",
            "39    0.051331\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Baseline code with contextual augmentation integration is ready.\n",
            "Further steps would involve defining a model, training, and evaluation.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Advanced Data Augmentation: Contextual Word Replacement using Masked LM ---\n",
        "print(\"\\nInitializing components for Contextual Word Augmentation...\")\n",
        "\n",
        "mlm_model_name = 'bert-base-uncased'\n",
        "unmasker = None # Initialize unmasker to None\n",
        "try:\n",
        "    # Using pipeline for easier Masked LM prediction\n",
        "    # Attempt to use GPU if available, otherwise it should default to CPU.\n",
        "    # The device parameter can explicitly be set to torch.device(\"cpu\") if GPU issues persist.\n",
        "    if torch.cuda.is_available():\n",
        "        # Check if CUDA is truly functional beyond just being available\n",
        "        try:\n",
        "            torch.cuda.init() # Attempt to initialize CUDA\n",
        "            print(\"CUDA seems available and initialized. Attempting to use GPU for pipeline.\")\n",
        "            unmasker = pipeline('fill-mask', model=mlm_model_name, tokenizer=mlm_model_name, top_k=5, device=0) # Use first GPU\n",
        "        except Exception as cuda_init_error:\n",
        "            print(f\"CUDA available but initialization failed: {cuda_init_error}. Falling back to CPU for pipeline.\")\n",
        "            unmasker = pipeline('fill-mask', model=mlm_model_name, tokenizer=mlm_model_name, top_k=5, device=-1) # Explicitly CPU\n",
        "    else:\n",
        "        print(\"CUDA not available. Using CPU for pipeline.\")\n",
        "        unmasker = pipeline('fill-mask', model=mlm_model_name, tokenizer=mlm_model_name, top_k=5) # Defaults to CPU (device=-1)\n",
        "    \n",
        "    if unmasker:\n",
        "        print(f\"Masked LM pipeline ('{mlm_model_name}') initialized successfully on device: {unmasker.device}.\")\n",
        "except Exception as e:\n",
        "    # This broad exception will catch OSErrors during pipeline init if CUDA libs are missing\n",
        "    # or other initialization issues.\n",
        "    print(f\"Error initializing Masked LM pipeline: {e}\")\n",
        "    print(\"Data augmentation will be SKIPPED.\")\n",
        "    print(\"Common reasons: Missing CUDA libraries (if GPU attempted), Hugging Face model download issue (check internet), or other transformer/PyTorch setup problems.\")\n",
        "    unmasker = None # Ensure it's None if any error occurred\n",
        "\n",
        "def contextual_word_replacement_augmentation(text, unmasker_pipeline, mask_token=\"[MASK]\", num_augmentations=1, mask_ratio=0.15):\n",
        "    if unmasker_pipeline is None:\n",
        "        return [text]\n",
        "\n",
        "    augmented_texts = []\n",
        "    original_words = text.split()\n",
        "\n",
        "    if len(original_words) < 5:\n",
        "        return [text] * num_augmentations\n",
        "\n",
        "    for _ in range(num_augmentations):\n",
        "        words_to_augment = list(original_words)\n",
        "        num_words_to_mask = max(1, int(len(words_to_augment) * mask_ratio))\n",
        "        num_words_to_mask = min(num_words_to_mask, len(words_to_augment))\n",
        "        \n",
        "        # Get indices of words to be masked. We sort them to process from start to end\n",
        "        # but the actual masking strategy inside the loop will handle context.\n",
        "        indices_to_potentially_mask = sorted(random.sample(range(len(words_to_augment)), num_words_to_mask))\n",
        "\n",
        "        temp_augmented_words = list(words_to_augment)\n",
        "\n",
        "        for word_idx_to_mask in indices_to_potentially_mask:\n",
        "            # Create a copy for masking this specific word, using the current state of temp_augmented_words\n",
        "            current_context_words = list(temp_augmented_words)\n",
        "            if word_idx_to_mask >= len(current_context_words): continue\n",
        "\n",
        "            original_word_at_idx = current_context_words[word_idx_to_mask]\n",
        "            current_context_words[word_idx_to_mask] = mask_token\n",
        "            single_masked_input_text = \" \".join(current_context_words)\n",
        "\n",
        "            try:\n",
        "                predictions = unmasker_pipeline(single_masked_input_text)\n",
        "                chosen_replacement = None\n",
        "                \n",
        "                if predictions and isinstance(predictions, list):\n",
        "                    # The pipeline with top_k returns a list of potential fills for each mask.\n",
        "                    # If single_masked_input_text has one [MASK], predictions is like:\n",
        "                    # [[{'score': ..., 'token_str': 'word1'}, {'score': ..., 'token_str': 'word2'}]]\n",
        "                    # OR if multiple masks are handled differently by some model versions (less common for fill-mask):\n",
        "                    # [{'score': ..., 'token_str': 'word1'}, ...] for the first mask\n",
        "                    \n",
        "                    # Assuming predictions[0] is a list of dicts for the first (and only) mask\n",
        "                    potential_fills = predictions[0] if isinstance(predictions[0], list) else predictions\n",
        "\n",
        "                    for pred_option in potential_fills:\n",
        "                        if isinstance(pred_option, dict) and pred_option['token_str'].strip().lower() != original_word_at_idx.lower():\n",
        "                            chosen_replacement = pred_option['token_str'].strip()\n",
        "                            break\n",
        "                    if not chosen_replacement and potential_fills: # Fallback to top prediction\n",
        "                         if isinstance(potential_fills[0], dict):\n",
        "                            chosen_replacement = potential_fills[0]['token_str'].strip()\n",
        "                \n",
        "                if chosen_replacement:\n",
        "                    temp_augmented_words[word_idx_to_mask] = chosen_replacement # Update the main list for this augmentation\n",
        "            except Exception as e:\n",
        "                # print(f\"Warning: Augmentation step failed for mask at index {word_idx_to_mask}. Error: {e}\")\n",
        "                pass \n",
        "        \n",
        "        final_augmented_text = \" \".join(temp_augmented_words)\n",
        "        augmented_texts.append(final_augmented_text)\n",
        "\n",
        "    return augmented_texts if augmented_texts else [text]\n",
        "\n",
        "\n",
        "# --- Apply Augmentation ---\n",
        "dataset_with_aug = dataset.copy()\n",
        "dataset_with_aug['is_augmented'] = False\n",
        "\n",
        "if unmasker:\n",
        "    AUGMENTATION_TARGET_COUNT = int(dataset.shape[0] * 0.25) # Example: Augment to add 25% more samples\n",
        "    NUM_AUGMENTATIONS_PER_SELECTED_SAMPLE = 1\n",
        "    AUGMENTATION_MASK_RATIO = 0.10 # Mask 10% of words\n",
        "\n",
        "    print(f\"\\nApplying contextual word replacement augmentation to generate approx. {AUGMENTATION_TARGET_COUNT} new samples...\")\n",
        "    new_rows = []\n",
        "    \n",
        "    num_original_samples_to_augment = min(AUGMENTATION_TARGET_COUNT, len(dataset))\n",
        "    if num_original_samples_to_augment == 0 and AUGMENTATION_TARGET_COUNT > 0:\n",
        "        print(\"Warning: No original samples available to augment from, but augmentation target > 0.\")\n",
        "\n",
        "    candidate_indices = dataset.index.tolist()\n",
        "    if num_original_samples_to_augment < len(dataset):\n",
        "         indices_to_augment = random.sample(candidate_indices, num_original_samples_to_augment)\n",
        "    else:\n",
        "         indices_to_augment = candidate_indices\n",
        "\n",
        "    for original_idx in tqdm(indices_to_augment, desc=\"Augmenting samples\"):\n",
        "        row = dataset.loc[original_idx]\n",
        "        original_text = row['text_input']\n",
        "        assignee_label = row['assignee_encoded']\n",
        "        original_summary, original_description, original_assignee, original_bug_id = row['Summary'], row['Description'], row['Assignee'], row['Bug_ID']\n",
        "\n",
        "        augmented_texts = contextual_word_replacement_augmentation(\n",
        "            original_text, unmasker, mask_token=unmasker.tokenizer.mask_token,\n",
        "            num_augmentations=NUM_AUGMENTATIONS_PER_SELECTED_SAMPLE, mask_ratio=AUGMENTATION_MASK_RATIO\n",
        "        )\n",
        "        for i, aug_text in enumerate(augmented_texts):\n",
        "            if aug_text != original_text: \n",
        "                new_rows.append({\n",
        "                    'Bug_ID': f\"{original_bug_id}_aug{i+1}\", 'Assignee': original_assignee,\n",
        "                    'Summary': original_summary, \n",
        "                    'Description': \"AUGMENTED: \" + (aug_text.split(\"| Description =\")[-1].strip() if \"| Description =\" in aug_text else aug_text),\n",
        "                    'Status': 'AUGMENTED_BUG_STATUS', 'text_input': aug_text,\n",
        "                    'assignee_encoded': assignee_label, 'is_augmented': True\n",
        "                })\n",
        "    \n",
        "    if new_rows:\n",
        "        augmented_df = pd.DataFrame(new_rows)\n",
        "        dataset_with_aug = pd.concat([dataset_with_aug, augmented_df], ignore_index=True)\n",
        "        print(f\"\\nShape of dataset after augmentation: {dataset_with_aug.shape}\")\n",
        "        print(f\"Number of augmented samples added: {len(augmented_df)}\")\n",
        "        \n",
        "        if len(augmented_df) > 0 and indices_to_augment:\n",
        "            print(\"\\nExample of augmentation:\")\n",
        "            example_original_idx = indices_to_augment[0]\n",
        "            print(f\"Original text (from index {example_original_idx}): {dataset.loc[example_original_idx]['text_input']}\")\n",
        "            corresponding_aug_sample = augmented_df[augmented_df['Bug_ID'].str.startswith(str(dataset.loc[example_original_idx]['Bug_ID']) + \"_aug\")]\n",
        "            if not corresponding_aug_sample.empty:\n",
        "                 print(f\"One augmented text for it: {corresponding_aug_sample.iloc[0]['text_input']}\")\n",
        "            else:\n",
        "                 print(f\"First augmented sample (could not find direct example match): {augmented_df.iloc[0]['text_input']}\")\n",
        "    else:\n",
        "        print(\"\\nNo augmented samples were effectively generated or added.\")\n",
        "else:\n",
        "    print(\"\\nSkipping augmentation as unmasker pipeline is not available (e.g., due to initialization error).\")\n",
        "\n",
        "# --- Post-Augmentation ---\n",
        "print(f\"\\nFinal dataset size: {dataset_with_aug.shape}\")\n",
        "\n",
        "dataset_with_aug['assignee_encoded'] = dataset_with_aug['assignee_encoded'].astype(int)\n",
        "\n",
        "if NUM_ACTUAL_CLS > 1:\n",
        "    X = dataset_with_aug['text_input']\n",
        "    y = dataset_with_aug['assignee_encoded']\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    except ValueError as e:\n",
        "        print(f\"Warning: Could not stratify during train_test_split due to: {e}. Splitting without stratification.\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of X_test: {X_test.shape}\")\n",
        "    if not y_train.empty:\n",
        "        print(f\"Train set class distribution (top 5 classes):\\n{y_train.value_counts(normalize=True).nlargest(5)}\")\n",
        "    if not y_test.empty:\n",
        "        print(f\"Test set class distribution (top 5 classes):\\n{y_test.value_counts(normalize=True).nlargest(5)}\")\n",
        "else:\n",
        "    print(\"Skipping train_test_split as NUM_ACTUAL_CLS <= 1\")\n",
        "\n",
        "print(\"\\nBaseline code with contextual augmentation integration is ready.\")\n",
        "print(\"Further steps would involve defining a model, training, and evaluation.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: 18 classes have fewer than 2 samples. Proceeding without stratification.\n",
            "Small classes: ['Martin Liška', 'Andreas Schwab', 'Oleg Endo', 'Rafaël Carré', 'Richard Earnshaw']...\n",
            "Train set size: 2100, Test set size: 526\n"
          ]
        }
      ],
      "source": [
        "# --- Train/Test Split ---\n",
        "texts = dataset_with_aug['text_input'].tolist()\n",
        "labels = dataset_with_aug['assignee_encoded'].tolist()\n",
        "\n",
        "# Stratify only if all classes have at least MIN_CLASS_REPRESENTATION samples\n",
        "assignee_counts = dataset_with_aug['Assignee'].value_counts()\n",
        "small_classes = assignee_counts[assignee_counts < MIN_CLASS_REPRESENTATION].index.tolist()\n",
        "\n",
        "stratify_labels = None\n",
        "if not small_classes: \n",
        "    stratify_labels = labels\n",
        "    print(f\"Attempting stratified split. All {NUM_ACTUAL_CLS} classes have at least {MIN_CLASS_REPRESENTATION} samples.\")\n",
        "else:\n",
        "    print(f\"Warning: {len(small_classes)} classes have fewer than {MIN_CLASS_REPRESENTATION} samples. Proceeding without stratification.\")\n",
        "    print(f\"Small classes: {small_classes[:5]}...\")\n",
        "\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels, test_size=VALID_SET_SIZE, random_state=42, shuffle=True, stratify=stratify_labels\n",
        ")\n",
        "\n",
        "print(f\"Train set size: {len(train_texts)}, Test set size: {len(test_texts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Prepare data for DataLoader (list of dicts) ---\n",
        "def create_data_list(texts, labels):\n",
        "    return [{'text': text, 'label': label} for text, label in zip(texts, labels)]\n",
        "\n",
        "train_data_list = create_data_list(train_texts, train_labels)\n",
        "test_data_list = create_data_list(test_texts, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Collate Function  ---\n",
        "def collate_with_glove(batch, hf_tokenizer, glove_word_vectors, embedding_dimension, unk_word_embedding):\n",
        "    labels_list = [item['label'] for item in batch]\n",
        "    texts_list = [item['text'] for item in batch]\n",
        "\n",
        "    # Ensure labels are LongTensors for CrossEntropyLoss\n",
        "    labels = torch.LongTensor(labels_list)\n",
        "\n",
        "    all_sequences_as_vecs = []\n",
        "    for text_item in texts_list:\n",
        "        string_tokens = hf_tokenizer.tokenize(str(text_item)) # Ensure text_item is string\n",
        "\n",
        "        if not string_tokens:\n",
        "            all_sequences_as_vecs.append(torch.tensor(unk_word_embedding, dtype=torch.float).unsqueeze(0))\n",
        "            continue\n",
        "\n",
        "        current_sequence_embeddings = []\n",
        "        for token_str in string_tokens:\n",
        "            vec = glove_word_vectors.get(token_str, unk_word_embedding)\n",
        "            current_sequence_embeddings.append(torch.tensor(vec, dtype=torch.float))\n",
        "\n",
        "        if not current_sequence_embeddings:\n",
        "            all_sequences_as_vecs.append(torch.tensor(unk_word_embedding, dtype=torch.float).unsqueeze(0))\n",
        "        else:\n",
        "            all_sequences_as_vecs.append(torch.stack(current_sequence_embeddings))\n",
        "\n",
        "    vecs_padded = pad_sequence(all_sequences_as_vecs, batch_first=False, padding_value=0.0)\n",
        "    return vecs_padded, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataLoaders created for gcc_data.\n"
          ]
        }
      ],
      "source": [
        "# --- Create DataLoaders ---\n",
        "if glove_vectors_map is not None and train_data_list and test_data_list:\n",
        "    collate_fn_custom = partial(collate_with_glove,\n",
        "                                 hf_tokenizer=tokenizer,\n",
        "                                 glove_word_vectors=glove_vectors_map,\n",
        "                                 embedding_dimension=GLOVE_EMBEDDING_DIM,\n",
        "                                 unk_word_embedding=unk_embedding)\n",
        "\n",
        "    train_loader = DataLoader(train_data_list, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_custom)\n",
        "    test_loader = DataLoader(test_data_list, batch_size=BATCH_SIZE, collate_fn=collate_fn_custom)\n",
        "    print(\"DataLoaders created for gcc_data.\")\n",
        "else:\n",
        "    print(\"GloVe vectors not loaded or data lists are empty. Cannot create DataLoaders.\")\n",
        "    train_loader = None\n",
        "    test_loader = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Utility Classes and CNN Model (largely unchanged) ---\n",
        "class AverageMeter(object):\n",
        "    def __init__(self): self.reset()\n",
        "    def reset(self): self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val; self.sum += val * n; self.count += n; self.avg = self.sum / self.count\n",
        "\n",
        "class CNNModel1(nn.Module):\n",
        "    def __init__(self, embed_dim, filter_sizes, num_filters_per_size, num_classes, dropout_rate):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1d_list = nn.ModuleList(\n",
        "            [\n",
        "                nn.Conv1d(in_channels=embed_dim,\n",
        "                          out_channels=n_filters,\n",
        "                          kernel_size=f_size)\n",
        "                for f_size, n_filters in zip(filter_sizes, num_filters_per_size)\n",
        "            ]\n",
        "        )\n",
        "        # Calculate total number of filters correctly\n",
        "        total_filters = sum(num_filters_per_size)\n",
        "        self.fc = nn.Linear(total_filters, num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (max_seq_length, batch_size, embedding_dim)\n",
        "        x = x.permute(1, 2, 0) # (batch_size, embedding_dim, max_seq_length)\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv1d_list:\n",
        "            conv_output = conv_layer(x)\n",
        "            conv_output = F.relu(conv_output)\n",
        "            conv_output = F.max_pool1d(conv_output, kernel_size=conv_output.size(2)).squeeze(2)\n",
        "            conv_outputs.append(conv_output)\n",
        "\n",
        "        x_concatenated = torch.cat(conv_outputs, dim=1)\n",
        "        x_dropped_out = self.dropout(x_concatenated)\n",
        "        logits = self.fc(x_dropped_out)\n",
        "        return logits\n",
        "\n",
        "class CNNModel2(nn.Module):\n",
        "    def __init__(self, \n",
        "                    embed_dim,\n",
        "                    filter_sizes,\n",
        "                    num_filters_per_size,\n",
        "                    num_classes,\n",
        "                    dropout_rate,\n",
        "                    hidden_dim_fc\n",
        "                 ):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1d_list = nn.ModuleList(\n",
        "            [\n",
        "                nn.Conv1d(in_channels=embed_dim,\n",
        "                          out_channels=n_filters,\n",
        "                          kernel_size=f_size)\n",
        "                for f_size, n_filters in zip(filter_sizes, num_filters_per_size)\n",
        "            ]\n",
        "        )\n",
        "        # Calculate total number of filters correctly\n",
        "        total_filters = sum(num_filters_per_size)\n",
        "        self.fc1 = nn.Linear(total_filters, hidden_dim_fc)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_dim_fc, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (max_seq_length, batch_size, embedding_dim)\n",
        "        x = x.permute(1, 2, 0) # (batch_size, embedding_dim, max_seq_length)\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv1d_list:\n",
        "            conv_output = conv_layer(x)\n",
        "            conv_output = F.relu(conv_output)\n",
        "            conv_output = F.max_pool1d(conv_output, kernel_size=conv_output.size(2)).squeeze(2)\n",
        "            conv_outputs.append(conv_output)\n",
        "\n",
        "        x_concatenated = torch.cat(conv_outputs, dim=1)\n",
        "        x_dropped_out1 = self.dropout(x_concatenated)\n",
        "        x_fc1 = F.relu(self.fc1(x_dropped_out1))\n",
        "        x_dropped_out2 = self.dropout(x_fc1)\n",
        "        logits = self.fc2(x_dropped_out2)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Training and Validation Functions (largely unchanged) ---\n",
        "def train_one_epoch(model, dataloader, loss_function, optim, current_epoch=None):\n",
        "    model.train()\n",
        "    loss_meter = AverageMeter()\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    tepoch = tqdm(dataloader, unit=\"batch\")\n",
        "    if current_epoch is not None: tepoch.set_description(f\"Epoch {current_epoch+1}\")\n",
        "    for inputs, targets in tepoch:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        optim.zero_grad(); loss.backward(); optim.step()\n",
        "        loss_meter.update(loss.item(), inputs.size(1)) # batch_size is second dim of permuted input\n",
        "        _, predicted_labels = torch.max(outputs.data, 1)\n",
        "        total_samples += targets.size(0)\n",
        "        correct_predictions += (predicted_labels == targets).sum().item()\n",
        "        tepoch.set_postfix(loss=loss_meter.avg, accuracy=100. * correct_predictions / total_samples if total_samples > 0 else 0)\n",
        "    return model, loss_meter.avg, (100. * correct_predictions / total_samples if total_samples > 0 else 0)\n",
        "\n",
        "def validate_model(model, dataloader, loss_function):\n",
        "    model.eval()\n",
        "    loss_meter = AverageMeter()\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad(), tqdm(dataloader, unit=\"batch\", desc=\"Validating\") as tepoch:\n",
        "        for inputs, targets in tepoch:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            loss_meter.update(loss.item(), inputs.size(1))\n",
        "            _, predicted_labels = torch.max(outputs.data, 1)\n",
        "            total_samples += targets.size(0)\n",
        "            correct_predictions += (predicted_labels == targets).sum().item()\n",
        "            tepoch.set_postfix(loss=loss_meter.avg, accuracy=100. * correct_predictions / total_samples if total_samples > 0 else 0)\n",
        "    return loss_meter.avg, (100. * correct_predictions / total_samples if total_samples > 0 else 0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using device: cuda\n",
            "\n",
            "Sample batch - X shape: torch.Size([2563, 32, 300]), Y shape: torch.Size([32])\n",
            "\n",
            "CNN Model Initialized with 82 output classes.\n",
            "CNNModel(\n",
            "  (conv1d_list): ModuleList(\n",
            "    (0): Conv1d(300, 512, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 512, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 512, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (fc1): Linear(in_features=1536, out_features=256, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=256, out_features=82, bias=True)\n",
            ")\n",
            "\n",
            "--- Starting Model Training ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  77%|███████▋  | 51/66 [00:15<00:04,  3.35batch/s, accuracy=17.6, loss=3.65]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 872.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 448.00 MiB is free. Including non-PyTorch memory, this process has 3.36 GiB memory in use. Of the allocated memory 3.15 GiB is allocated by PyTorch, and 91.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Starting Model Training ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     cnn_model, train_loss, train_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     valid_loss, valid_acc = validate_model(cnn_model, test_loader, criterion)\n\u001b[32m     42\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss); history[\u001b[33m'\u001b[39m\u001b[33mvalid_loss\u001b[39m\u001b[33m'\u001b[39m].append(valid_loss)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, dataloader, loss_function, optim, current_epoch)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m tepoch:\n\u001b[32m     10\u001b[39m     inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     loss = loss_function(outputs, targets)\n\u001b[32m     13\u001b[39m     optim.zero_grad(); loss.backward(); optim.step()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/nlp-project-UsGAi-Qg-py3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/nlp-project-UsGAi-Qg-py3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mCNNModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     68\u001b[39m conv_outputs = []\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m conv_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.conv1d_list:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     conv_output = \u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     conv_output = F.relu(conv_output)\n\u001b[32m     72\u001b[39m     conv_output = F.max_pool1d(conv_output, kernel_size=conv_output.size(\u001b[32m2\u001b[39m)).squeeze(\u001b[32m2\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/nlp-project-UsGAi-Qg-py3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/nlp-project-UsGAi-Qg-py3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/nlp-project-UsGAi-Qg-py3.13/lib/python3.13/site-packages/torch/nn/modules/conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/nlp-project-UsGAi-Qg-py3.13/lib/python3.13/site-packages/torch/nn/modules/conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 872.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 448.00 MiB is free. Including non-PyTorch memory, this process has 3.36 GiB memory in use. Of the allocated memory 3.15 GiB is allocated by PyTorch, and 91.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIM_VALUE = 300\n",
        "N_FILTERS_LIST = [512, 512, 512]\n",
        "FILTER_SIZES_LIST = [3, 4, 5]\n",
        "OUTPUT_DIM_VALUE = NUM_ACTUAL_CLS\n",
        "DROPOUT_RATE_VALUE = 0.5\n",
        "HIDDEN_DIM_FC_VALUE = 256\n",
        "\n",
        "print(f\"\\nUsing device: {DEVICE}\")\n",
        "# Test one batch\n",
        "try:\n",
        "    x_batch, y_batch = next(iter(train_loader))\n",
        "    print(f\"\\nSample batch - X shape: {x_batch.shape}, Y shape: {y_batch.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error getting a batch from train_loader (might be empty or an issue with collate_fn): {e}\")\n",
        "    # exit() # Exit if we can't even get a batch\n",
        "\n",
        "# Initialize model, loss, optimizer\n",
        "cnn_model = CNNModel(\n",
        "                        embed_dim=GLOVE_EMBEDDING_DIM,\n",
        "                        filter_sizes=FILTER_SIZES_LIST,\n",
        "                        num_filters_per_size=N_FILTERS_LIST,\n",
        "                        num_classes=NUM_ACTUAL_CLS, # Use dynamic number of classes\n",
        "                        dropout_rate=DROPOUT_RATE_VALUE,\n",
        "                        hidden_dim_fc=HIDDEN_DIM_FC_VALUE\n",
        "                    ).to(DEVICE)\n",
        "\n",
        "print(f\"\\nCNN Model Initialized with {NUM_ACTUAL_CLS} output classes.\")\n",
        "print(cnn_model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "# optimizer = optim.SGD(cnn_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, momentum=0.9)\n",
        "\n",
        "\n",
        "history = {'train_loss': [], 'valid_loss': [], 'train_acc': [], 'valid_acc': []}\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "for epoch_idx in range(NUM_EPOCHS):\n",
        "    cnn_model, train_loss, train_acc = train_one_epoch(cnn_model, train_loader, criterion, optimizer, epoch_idx)\n",
        "    valid_loss, valid_acc = validate_model(cnn_model, test_loader, criterion)\n",
        "    history['train_loss'].append(train_loss); history['valid_loss'].append(valid_loss)\n",
        "    history['train_acc'].append(train_acc); history['valid_acc'].append(valid_acc)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        torch.save(cnn_model.state_dict(), 'cnn_bug_assign_best.pt')\n",
        "        best_valid_loss = valid_loss\n",
        "        print('Model Saved as cnn_bug_assign_best.pt!')\n",
        "    print(f'Validation: Loss = {valid_loss:.4f}, Accuracy = {valid_acc:.2f}%')\n",
        "    print(\"-\" * 30)\n",
        "print(\"--- Training Finished ---\")\n",
        "\n",
        "if history['train_loss']:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1); plt.plot(history['train_loss'], label='Train Loss'); plt.plot(history['valid_loss'], label='Valid Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss vs. Epochs')\n",
        "    plt.subplot(1, 2, 2); plt.plot(history['train_acc'], label='Train Accuracy'); plt.plot(history['valid_acc'], label='Valid Accuracy')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.legend(); plt.title('Accuracy vs. Epochs')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "print(\"\\nScript execution completed.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp-project-UsGAi-Qg-py3.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
